
# importing libraries
import os
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os

import warnings




#  ==================  LOAD dataset ================= 
final_df2 = pd.read_csv('df_api_calls.csv')

# ================== Feature Engineering ====================

final_df2["LdrUnloadDll"]

# checking for all columns
final_df2.columns

# check for empty records
final_df2.isnull().sum()

# ## ==================1.2 Fiilling Empty or NaN values==================
# ===================== Filling all `NaN` (null) values in all `columns` with the `mean`
# ================== Fill NaN values in all columns with the mean of their respective columns
final_df2.fillna(final_df2.mean(), inplace=True)
df = final_df2.copy()

df.head()

#====================== 2.0 Scale Data or Feature Engineering=======================
# 
# 1. Slit data in train-test
# 2. **Scaling Data:**  standardization

# ###=================== 2.1 data spliting==================

# Separating the target from the predictors
y = df["Malware"]
X = df.drop("Malware", axis=1)

from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ###=================== 2.2 Scaling Data====================

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

# Fit and transform the scaler on the training set
X_train_scaled = scaler.fit_transform(X_train)

# Transform the testing set using the same scaler
X_test_scaled = scaler.transform(X_test)

#convert y_train to numpy array
y_train = np.array(y_train)


# # ==========================================3 Train Model=====================

# importing packages
from sklearn.naive_bayes import MultinomialNB, BernoulliNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score, accuracy_score
from sklearn.metrics import precision_recall_fscore_support
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix



### =================== MODEL MODEL ===================================
# ## ================= 3.1 A function for Model training===========================
#
# 1. Script to train the machine learning model
# 2. Script to extract `Accuracy` of the model


# building a general function for training the model

def model_train(model, X_train, X_test, y_train, y_test):
    # Print the name of the model being used
    print(" \n")
    print("====================================================================")
    print(f"Using Model: ========== {model.__class__.__name__} ===========")
    print(" \n")

    model.fit(X_train, y_train)
    y_pred_tr = model.predict(X_train)
    y_pred = model.predict(X_test)

    print("--------------------Testing Performance----------------------")
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy: {accuracy:.5f}")
    print(classification_report(y_test, y_pred))

    print("=======================================")
    print(" \n ")
    print("============Accuracy==========")
    print(f"Accuracy: {accuracy:.5f}")

    conf_matrix = confusion_matrix(y_test, y_pred)
    print("============= Recall ===================")

    # Calculate recall
    TP = conf_matrix[1, 1]  # True Positives
    FN = conf_matrix[1, 0]  # False Negatives
    recall = TP / (TP + FN)

    print(f'Recall: {recall:.5f}')

    print("============= Precision ===================")

    # Calculate precision
    TP = conf_matrix[1, 1]  # True Positives
    FP = conf_matrix[0, 1]  # False Positives
    precision = TP / (TP + FP)

    print(f'Precision: {precision:.5f}')

    print("============= F1 Score ===================")

    # Calculate precision and recall
    TP = conf_matrix[1, 1]  # True Positives
    FP = conf_matrix[0, 1]  # False Positives
    FN = conf_matrix[1, 0]  # False Negatives

    precision = TP / (TP + FP)
    recall = TP / (TP + FN)

    # Calculate F1 score
    f1_score = 2 * (precision * recall) / (precision + recall)

    print(f'F1 Score: {f1_score:.5f}')

    return y_pred




# ## =================  3.2 Random Forest ==========================
#  Random Forest: Random Forest builds a collection of decision trees, typically using the CART (Classification and Regression Trees) algorithm. 
# It grows each tree independently and combines their predictions through bagging (bootstrap aggregating) and averaging.


model = RandomForestClassifier(n_estimators=100, random_state=1)
y_pred1 = model_train(model, X_train, X_test, y_train, y_test)



# ## ======================== 3.3  Decision Tree ========================



model = DecisionTreeClassifier(random_state=42)
y_pred2 = model_train(model, X_train, X_test, y_train, y_test)

